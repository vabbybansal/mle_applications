{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99003e5a-567b-49f6-b4cc-da44c9b03b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3df45a32-9ca4-4910-bc96-ac735f8eb68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "233108d8-7537-4c9b-9bda-b67db9571774",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,    # Vocabulary size\n",
    "    \"context_length\": 1024, # Context length\n",
    "    \"emb_dim\": 768,         # Embedding dimension\n",
    "    \"n_heads\": 12,          # Number of attention heads\n",
    "    \"n_layers\": 12,         # Number of layers\n",
    "    \"drop_rate\": 0.1,       # Dropout rate\n",
    "    \"qkv_bias\": False       # Query-Key-Value bias\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3716c9ff-b714-4728-a35e-00a85efbaba6",
   "metadata": {},
   "source": [
    "# LayerNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57806299-b0ce-4794-9022-75964d78a14d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1115,  0.1204, -0.3696, -0.2404, -1.1969],\n",
       "        [ 0.2093, -0.9724, -0.7550,  0.3239, -0.1085]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "batch_example = torch.randn(2, 5)\n",
    "batch_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be62356d-1df7-4f04-a093-8bd3237cd8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c543db85-7443-4585-944a-64973b98d308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[-2.9802e-08],\n",
      "        [ 0.0000e+00]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "ln = LayerNorm(emb_dim=5)\n",
    "out_ln = ln(batch_example)\n",
    "\n",
    "mean = out_ln.mean(dim=-1, keepdim=True)\n",
    "var = out_ln.var(dim=-1, unbiased=False, keepdim=True)\n",
    "\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eaf64dcf-e2bb-4d41-9197-23a8693f5bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5528,  1.0693, -0.0223,  0.2656, -1.8654],\n",
      "        [ 0.9087, -1.3767, -0.9564,  1.1304,  0.2940]], grad_fn=<AddBackward0>)\n",
      "tensor([[ 0.3924,  0.9170, -0.0110,  0.1606, -0.0579],\n",
      "        [ 0.7435, -0.1161, -0.1620,  0.9844,  0.1810]],\n",
      "       grad_fn=<GeluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(out_ln)\n",
    "print(nn.GELU()(out_ln))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00bfc92-7b59-4eda-b4e7-9322bcb9d83c",
   "metadata": {},
   "source": [
    "# Feedforward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f1f3b51-e0a5-4b3d-a423-27e3aa801448",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, embed_dim):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(embed_dim, 4*embed_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(4*embed_dim, embed_dim),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a5480af-3743-47df-b28c-cc952a3fc6ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.2938,  0.2750, -0.2915, -0.1774,  0.0675, -0.3712,  0.1027],\n",
       "         [ 0.6098,  0.4351, -0.4272, -0.1102,  0.2877, -0.4949,  0.1296],\n",
       "         [ 0.5349,  0.4603, -0.4299, -0.1643,  0.2524, -0.4933,  0.1858]],\n",
       "\n",
       "        [[ 0.3170,  0.3319, -0.2710, -0.1806,  0.0505, -0.3808,  0.1284],\n",
       "         [ 0.3270,  0.2830, -0.2897, -0.2049,  0.0593, -0.3527,  0.1450],\n",
       "         [ 0.3536,  0.3837, -0.3053, -0.1027,  0.1574, -0.3907,  0.1756]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffn = FeedForward(7)\n",
    "x = torch.rand(2,3,7)\n",
    "ffn(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dff5382-499a-4188-9df5-df4291109b6d",
   "metadata": {},
   "source": [
    "# Transformer Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff548d1d-3d7c-4774-9c44-0b8f0f301b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout=-1, num_heads=2):\n",
    "        super().__init__()\n",
    "\n",
    "        assert (d_out % num_heads == 0)\n",
    "        \n",
    "        self.num_heads = num_heads\n",
    "        self.d_out = d_out\n",
    "        self.head_dim = d_out // num_heads\n",
    "\n",
    "        self.W_query = torch.nn.Parameter(torch.rand(d_in, d_out, device=device))\n",
    "        self.W_key = torch.nn.Parameter(torch.rand(d_in, d_out, device=device))\n",
    "        self.W_value = torch.nn.Parameter(torch.rand(d_in, d_out, device=device))\n",
    "        causal_mask = torch.triu(torch.ones(context_length, context_length, device=device), diagonal=1)\n",
    "        self.register_buffer(\"causal_mask\", causal_mask, persistent=False)\n",
    "\n",
    "        self.out_proj = nn.Linear(d_out, d_out, device=device)\n",
    "        \n",
    "        self.dropout = dropout\n",
    "        if dropout > 0.0:\n",
    "            self.dropout_layer = torch.nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        assert len(x.shape) == 3, print(f\"x should be 3 dimensional but found it as {len(x.shape)}\")\n",
    "        b, num_tokens, d_in = x.shape\n",
    "\n",
    "        Q = x @ self.W_query\n",
    "        K = x @ self.W_key\n",
    "        V = x @ self.W_value\n",
    "\n",
    "        Q = Q.view(b, num_tokens, self.num_heads, self.head_dim).transpose(1,2) # b, num_heads, tokens, embedding\n",
    "        K = K.view(b, num_tokens, self.num_heads, self.head_dim).transpose(1,2)\n",
    "        V = V.view(b, num_tokens, self.num_heads, self.head_dim).transpose(1,2)\n",
    "        \n",
    "        QKt = Q @ K.transpose(-2,-1)\n",
    "\n",
    "        # Apply causal mask        \n",
    "        QKt.masked_fill_(\n",
    "            self.causal_mask.bool()[:num_tokens, :num_tokens], # num_tokens makes it work for cases where batch has less tokens than context length\n",
    "            -torch.inf\n",
    "        )\n",
    "        \n",
    "        QKt = F.softmax(QKt / self.head_dim**0.5, dim=-1)\n",
    "        if self.dropout > 0.0:\n",
    "            QKt = self.dropout_layer(QKt)\n",
    "        \n",
    "        QKtV = (QKt @ V).transpose(1,2) # batch, num_tokens, num_heads, head_dim\n",
    "\n",
    "        QKtV = QKtV.contiguous().view(b, num_tokens, self.d_out)\n",
    "        QKtV = self.out_proj(QKtV)\n",
    "        return QKtV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34b40a4-8f8d-4310-820d-5355ac92b1a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e5378993-dd9a-4a86-9631-d72b24839859",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.attention = MultiHeadAttention(\n",
    "            d_in=cfg[\"emb_dim\"], \n",
    "            d_out=cfg[\"emb_dim\"], \n",
    "            context_length=cfg[\"context_length\"], \n",
    "            dropout=cfg[\"drop_rate\"], \n",
    "            num_heads=cfg[\"n_heads\"]\n",
    "        )\n",
    "        self.ff = FeedForward(cfg[\"emb_dim\"])\n",
    "        self.norm1 = nn.LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = nn.LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.dropout = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.attention(x)\n",
    "        x = self.dropout(x)\n",
    "        x = x + residual\n",
    "\n",
    "        residual = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.dropout(x)\n",
    "        x = x + residual\n",
    "\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "413068f3-c2c8-4216-a7ad-72a874100802",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "x = torch.rand(2, 7, 768).to(device)\n",
    "\n",
    "block = TransformerBlock(GPT_CONFIG_124M).to(device)\n",
    "output = block(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7bb10aea-55f2-4125-ae11-1edd81747cd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 7, 768])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0fb8a9-fa9a-4899-8817-3429103a1a70",
   "metadata": {},
   "source": [
    "# GPT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b81b5a4c-d420-4286-bce0-17fb6ab7ae6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9e3c8897-f933-4255-8353-df05caa12f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n",
    "        )\n",
    "\n",
    "        self.final_norm = nn.LayerNorm(cfg[\"emb_dim\"])\n",
    "\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "\n",
    "        self.out_head.weight = self.tok_emb.weight  # enable weight sharing between the input and output token matrices\n",
    "\n",
    "        self.register_buffer(\"pos_ids\", torch.arange(cfg[\"context_length\"]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len = x.shape\n",
    "        tok_embeds = self.tok_emb(x)\n",
    "        pos_embeds = self.pos_emb(self.pos_ids[:seq_len])\n",
    "\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "16673ebb-2785-4217-a2d3-fa99103e8ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[20185,   318,  4572,  4673,    13],\n",
      "        [37573,  4673,   318,  9552,    13]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "import tiktoken \n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "batch = []\n",
    "\n",
    "txt1 = \"AI is machine learning.\"\n",
    "txt2 = \"Machine learning is AI.\"\n",
    "\n",
    "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
    "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
    "\n",
    "batch = torch.stack(batch, dim=0).to(device)  # the sequence length needs to be the same for this to work\n",
    "\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1b44a22c-895d-4574-83a8-97df93bf591b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_model = GPTModel(GPT_CONFIG_124M).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4a584aac-83fe-474e-a1bd-0b2bbbf6b736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 124,412,160\n",
      "Trainable params: 124,412,160\n",
      "None\n",
      "Model+grads+buffers: 522.60 MiB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def count_params(model):\n",
    "    total = sum(p.numel() for p in model.parameters())\n",
    "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Total params: {total:,}\")\n",
    "    print(f\"Trainable params: {trainable:,}\")\n",
    "\n",
    "def model_bytes(model, include_grads=True):\n",
    "    param_bytes = sum(p.nelement() * p.element_size() for p in model.parameters())\n",
    "    buffer_bytes = sum(b.nelement() * b.element_size() for b in model.buffers())\n",
    "    grad_bytes = 0\n",
    "    if include_grads:\n",
    "        grad_bytes = sum(p.grad.nelement() * p.grad.element_size()\n",
    "                         for p in model.parameters() if p.grad is not None)\n",
    "    return param_bytes + buffer_bytes + grad_bytes\n",
    "\n",
    "def print_model_memory(model):\n",
    "    bytes_total = model_bytes(model, include_grads=True)\n",
    "    print(f\"Model+grads+buffers: {bytes_total/1024**2:.2f} MiB\")\n",
    "\n",
    "\n",
    "print(count_params(gpt_model))\n",
    "print(print_model_memory(gpt_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5fe126c7-278c-4879-aea4-dd212e260075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.1135e+00, -3.9195e+00,  2.5692e+01,  ...,  7.1352e+01,\n",
       "          -7.9276e+01,  2.4213e+01],\n",
       "         [ 3.9648e+01,  5.2325e+00,  3.6704e+00,  ...,  4.2743e+01,\n",
       "          -4.4488e+01,  1.0543e+00],\n",
       "         [ 3.8809e+01,  4.6302e+01,  6.6042e+00,  ..., -1.4842e+01,\n",
       "          -6.7325e+01, -4.6987e+00],\n",
       "         [-5.1707e+00,  1.0667e+01, -8.6553e+00,  ...,  1.7779e+01,\n",
       "          -5.1281e+01, -2.1124e+01],\n",
       "         [ 1.8735e+01,  5.9936e+01,  2.6030e+01,  ..., -6.5854e+00,\n",
       "          -8.4782e+01,  3.9035e-01]],\n",
       "\n",
       "        [[-4.0170e+01,  5.7704e+01,  2.9817e+01,  ...,  4.7025e+01,\n",
       "           4.8286e+00,  2.2369e+01],\n",
       "         [-5.1062e+01,  2.0255e+01,  3.9927e+01,  ...,  1.4520e+01,\n",
       "          -1.4429e+01, -4.6117e-03],\n",
       "         [-2.0727e+01,  1.1689e+01,  4.4933e+00,  ...,  5.2980e+01,\n",
       "          -3.2617e+01,  2.7573e+00],\n",
       "         [-9.5684e+00,  2.4166e+01,  2.7835e+01,  ...,  2.8095e-01,\n",
       "          -1.8059e+01,  9.4250e+00],\n",
       "         [-2.3676e+01,  2.4165e+01,  3.0748e+01,  ...,  1.3382e+00,\n",
       "          -3.3386e+01, -2.0234e+01]]], device='cuda:0',\n",
       "       grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_model(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b337423d-4592-4565-a78f-4e54bb1acd2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
