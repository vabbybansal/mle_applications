{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1706443600907,
     "user": {
      "displayName": "Vaibhav Bansal",
      "userId": "03259254199963156033"
     },
     "user_tz": -330
    },
    "id": "IpoJjHRzCfgN"
   },
   "outputs": [],
   "source": [
    "# Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation\n",
    "\n",
    "# https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\n",
    "# https://github.com/bentrevett/pytorch-seq2seq/blob/master/2%20-%20Learning%20Phrase%20Representations%20using%20RNN%20Encoder-Decoder%20for%20Statistical%20Machine%20Translation.ipynb\n",
    "# https://github.com/bentrevett/pytorch-seq2seq/blob/master/3%20-%20Neural%20Machine%20Translation%20by%20Jointly%20Learning%20to%20Align%20and%20Translate.ipynb\n",
    "# Comments: https://colab.research.google.com/drive/1NmWujB2PoJk24uOwZ4cAfX3O8cZyigyf\n",
    "# https://github.com/bentrevett/pytorch-seq2seq/blob/master/assets/seq2seq7.png\n",
    "# https://www.youtube.com/watch?v=BSSoEtv5jvQ&list=PLmZlBIcArwhPHmHzyM_cZJQ8_v5paQJTV&index=7\n",
    "# https://machinelearningmastery.com/the-luong-attention-mechanism/\n",
    "# https://github.com/spro/practical-pytorch/blob/master/seq2seq-translation/seq2seq-translation.ipynb\n",
    "# https://github.com/tensorflow/nmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1706443600907,
     "user": {
      "displayName": "Vaibhav Bansal",
      "userId": "03259254199963156033"
     },
     "user_tz": -330
    },
    "id": "4X1cgGDCC1SU"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 6325,
     "status": "ok",
     "timestamp": 1706443607230,
     "user": {
      "displayName": "Vaibhav Bansal",
      "userId": "03259254199963156033"
     },
     "user_tz": -330
    },
    "id": "E7Da-Pm0C1ky"
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27969,
     "status": "ok",
     "timestamp": 1706443635191,
     "user": {
      "displayName": "Vaibhav Bansal",
      "userId": "03259254199963156033"
     },
     "user_tz": -330
    },
    "id": "hkwI32QnIQlt",
    "outputId": "c28d343f-a4f2-4c8f-b1a6-e62a7a63a8f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "# Variables\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "PAD_token = 2\n",
    "is_ignore_pads = True\n",
    "MAX_LENGTH = 10\n",
    "hidden_size = 128\n",
    "batch_size = 1024\n",
    "epochs = 200\n",
    "SPLIT_RATIO = 0.95\n",
    "\n",
    "\n",
    "ENG_PREFIXES = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "# Data location\n",
    "file_path = 'data/eng-fra.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1706443635191,
     "user": {
      "displayName": "Vaibhav Bansal",
      "userId": "03259254199963156033"
     },
     "user_tz": -330
    },
    "id": "MJQCuQe_C4gD"
   },
   "outputs": [],
   "source": [
    "# Language class handler\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"<SOS>\", 1: \"<EOS>\", 2:\"<PAD>\"}\n",
    "        self.n_words = 3  # Count SOS, EOS and PAD_token\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "\n",
    "class PreProcess(object):\n",
    "  # Turn a Unicode string to plain ASCII, thanks to\n",
    "  # https://stackoverflow.com/a/518232/2809427\n",
    "  def unicodeToAscii(s):\n",
    "      return ''.join(\n",
    "          c for c in unicodedata.normalize('NFD', s)\n",
    "          if unicodedata.category(c) != 'Mn'\n",
    "      )\n",
    "\n",
    "  # Lowercase, trim, and remove non-letter characters\n",
    "  def normalizeString(s):\n",
    "      s = PreProcess.unicodeToAscii(s.lower().strip())\n",
    "      s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "      s = re.sub(r\"[^a-zA-Z!?]+\", r\" \", s)\n",
    "      return s.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1706443635191,
     "user": {
      "displayName": "Vaibhav Bansal",
      "userId": "03259254199963156033"
     },
     "user_tz": -330
    },
    "id": "muq8MZ6zGkUO"
   },
   "outputs": [],
   "source": [
    "class DataHandler(object):\n",
    "\n",
    "  # read langs and create lang objects, and pairs\n",
    "  def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open(file_path, encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[PreProcess.normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "  # filter pairs with length < max length + containing the eng_prefixes as mentioned in eng_prefixes\n",
    "  def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH\n",
    "        # and \\\n",
    "        # p[1].startswith(ENG_PREFIXES)\n",
    "\n",
    "  # filter pairs\n",
    "  def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if DataHandler.filterPair(pair)]\n",
    "\n",
    "  # Read data, filter data, register language objects\n",
    "  def prepareData(lang1, lang2, reverse=False):\n",
    "\n",
    "    # initiate language objects, and get pairs\n",
    "    input_lang, output_lang, pairs = DataHandler.readLangs(lang1, lang2, reverse)\n",
    "\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = DataHandler.filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "\n",
    "    # Register pairs with lang objects\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1706443635191,
     "user": {
      "displayName": "Vaibhav Bansal",
      "userId": "03259254199963156033"
     },
     "user_tz": -330
    },
    "id": "89jC4beJDXJg"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class DataLoaderHandler(object):\n",
    "\n",
    "  def sentenceFromIndices(lang, indices):\n",
    "      return ' '.join([lang.index2word[index] for index in indices])\n",
    "\n",
    "  def outputLangTokensFromIndices(lang, indices):\n",
    "      return [lang.index2word[index] for index in indices]\n",
    "\n",
    "  # create a list of token-indices from a list of token\n",
    "  def indexesFromSentence(lang, sentence):\n",
    "      return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "  # create tensor from sentence\n",
    "  def tensorFromSentence(lang, sentence):\n",
    "      indexes = DataLoaderHandler.indexesFromSentence(lang, sentence)\n",
    "      indexes.append(EOS_token)\n",
    "      return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1)\n",
    "\n",
    "  # create tensors from pair of sentences\n",
    "  def tensorsFromPair(pair):\n",
    "      input_tensor = DataLoaderHandler.tensorFromSentence(input_lang, pair[0])\n",
    "      target_tensor = DataLoaderHandler.tensorFromSentence(output_lang, pair[1])\n",
    "      return (input_tensor, target_tensor)\n",
    "\n",
    "  def split_train_test(pairs, split_ratio):\n",
    "\n",
    "    # Shuffle the data to ensure randomness\n",
    "    random.shuffle(pairs)\n",
    "\n",
    "    # Calculate the split indices\n",
    "    split_idx = int(len(pairs) * split_ratio)\n",
    "\n",
    "    # Split the data into train and test sets\n",
    "    train_pairs = pairs[:split_idx]\n",
    "    test_pairs = pairs[split_idx:]\n",
    "\n",
    "    # Optionally, if you want to further use the data as lists instead of references\n",
    "    train_pairs = list(train_pairs)\n",
    "    test_pairs = list(test_pairs)\n",
    "\n",
    "    return train_pairs, test_pairs\n",
    "\n",
    "  def tokenize_into_numpy_arrays(pairs, n, input_lang, output_lang):\n",
    "    # TODO: TRY INPUT AS VARIABLE LENGTH\n",
    "    # Init numpy arrays for timesteps with zeros. Should this be something else other than zeros to mark an empty token? (Since 0 is taken by SOS token)\n",
    "\n",
    "    input_ids = np.full((n, MAX_LENGTH), PAD_token, dtype=np.int32)\n",
    "    target_ids = np.full((n, MAX_LENGTH), PAD_token, dtype=np.int32)\n",
    "    # input_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
    "    # target_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
    "\n",
    "    for idx, (inp, tgt) in enumerate(pairs):\n",
    "        # Get list of token-indices\n",
    "        inp_ids = DataLoaderHandler.indexesFromSentence(input_lang, inp)\n",
    "        tgt_ids = DataLoaderHandler.indexesFromSentence(output_lang, tgt)\n",
    "\n",
    "        # Append <end of string> tokens\n",
    "        inp_ids.append(EOS_token)\n",
    "        tgt_ids.append(EOS_token)\n",
    "\n",
    "        # Assign token indices in the main array\n",
    "        input_ids[idx, :len(inp_ids)] = inp_ids\n",
    "        target_ids[idx, :len(tgt_ids)] = tgt_ids\n",
    "    return input_ids, target_ids\n",
    "\n",
    "  # generate data loader\n",
    "  def get_dataloader(batch_size):\n",
    "      # prepare language data\n",
    "      input_lang, output_lang, pairs = DataHandler.prepareData('eng', 'fra', True)\n",
    "\n",
    "      n = len(pairs)\n",
    "\n",
    "      train_pairs, test_pairs = DataLoaderHandler.split_train_test(pairs, SPLIT_RATIO)\n",
    "      n_train, n_test = len(train_pairs), len(test_pairs)\n",
    "\n",
    "      train_input_ids, train_target_ids = DataLoaderHandler.tokenize_into_numpy_arrays(train_pairs, n_train, input_lang, output_lang)\n",
    "      train_data = TensorDataset(\n",
    "                      torch.LongTensor(train_input_ids).to(device),\n",
    "                      torch.LongTensor(train_target_ids).to(device)\n",
    "      )\n",
    "\n",
    "      test_input_ids, test_target_ids = DataLoaderHandler.tokenize_into_numpy_arrays(test_pairs, n_test, input_lang, output_lang)\n",
    "      test_data = TensorDataset(\n",
    "                      torch.LongTensor(test_input_ids).to(device),\n",
    "                      torch.LongTensor(test_target_ids).to(device)\n",
    "      )\n",
    "\n",
    "      # Create a sampler\n",
    "      train_sampler = RandomSampler(train_data)\n",
    "      test_sampler = RandomSampler(test_data)\n",
    "\n",
    "      # Create a torch dataloader\n",
    "      train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "      test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=n_test)\n",
    "\n",
    "      print(f\"Train and Test Dataset # samples: {len(train_data)}, {len(test_data)}\")\n",
    "      print(f\"Train and Test Dataloader # batches: {len(train_dataloader)}, {len(test_dataloader)}\")\n",
    "\n",
    "      return input_lang, output_lang, train_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9445,
     "status": "ok",
     "timestamp": 1706443644633,
     "user": {
      "displayName": "Vaibhav Bansal",
      "userId": "03259254199963156033"
     },
     "user_tz": -330
    },
    "id": "sJoyZiRuojNA",
    "outputId": "70d627c4-5727-4304-a4e5-18853fc386a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 135842 sentence pairs\n",
      "Trimmed to 105692 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "fra 17865\n",
      "eng 10699\n",
      "Train and Test Dataset # samples: 100407, 5285\n",
      "Train and Test Dataloader # batches: 3138, 1\n"
     ]
    }
   ],
   "source": [
    "# Prepare Data\n",
    "# input_lang, output_lang, pairs = DataHandler.prepareData('eng', 'fra', True)\n",
    "# print(random.choice(pairs))\n",
    "\n",
    "input_lang, output_lang, train_dataloader, test_dataloader = DataLoaderHandler.get_dataloader(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TCOFSxKeDkEB"
   },
   "source": [
    "**Helpers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1706443644633,
     "user": {
      "displayName": "Vaibhav Bansal",
      "userId": "03259254199963156033"
     },
     "user_tz": -330
    },
    "id": "UNGIszhqDjle"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "class Helpers(object):\n",
    "\n",
    "  def asMinutes(s):\n",
    "      m = math.floor(s / 60)\n",
    "      s -= m * 60\n",
    "      return '%dm %ds' % (m, s)\n",
    "\n",
    "  def timeSince(since, percent):\n",
    "      now = time.time()\n",
    "      s = now - since\n",
    "      es = s / (percent)\n",
    "      rs = es - s\n",
    "      return '%s (- %s)' % (Helpers.asMinutes(s), Helpers.asMinutes(rs))\n",
    "\n",
    "  def showPlot(points):\n",
    "      plt.figure()\n",
    "      fig, ax = plt.subplots()\n",
    "      # this locator puts ticks at regular intervals\n",
    "      loc = ticker.MultipleLocator(base=0.2)\n",
    "      ax.yaxis.set_major_locator(loc)\n",
    "      plt.plot(points)\n",
    "      plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qViMMrjBDnlZ"
   },
   "source": [
    "The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 689,
     "status": "ok",
     "timestamp": 1706443645320,
     "user": {
      "displayName": "Vaibhav Bansal",
      "userId": "03259254199963156033"
     },
     "user_tz": -330
    },
    "id": "wQZI4vkXDJ2E"
   },
   "outputs": [],
   "source": [
    "# in: keys and query vector\n",
    "# shapes: (batch_size, time_steps, hidden_size); (batch_size, 1, hidden_size)\n",
    "class BhadanauAttentionBeforeOutput(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_size):\n",
    "        super(BhadanauAttentionBeforeOutput, self).__init__()\n",
    "\n",
    "        self.W_keys = nn.Linear(hidden_size, hidden_size)\n",
    "        self.W_query = nn.Linear(hidden_size, hidden_size)\n",
    "        self.W_combined = nn.Linear(hidden_size, 1)  # out shape: (batch_size, time_steps, 1)\n",
    "\n",
    "    def forward(self, keys, query):\n",
    "\n",
    "        trans_keys = self.W_keys(keys) # (batch_size, time_steps, hidden_size)\n",
    "        trans_query = self.W_query(query) # (batch_size, time_steps, hidden_size)\n",
    "\n",
    "        combine = trans_keys + trans_query # (batch_size, time_steps, hidden_size)\n",
    "        relu_combine = F.relu(combine) # (batch_size, time_steps, hidden_size)\n",
    "\n",
    "        scores_raw = self.W_combined(relu_combine) # (batch_size, time_steps, 1)\n",
    "\n",
    "        # reshape\n",
    "        scores_raw = scores_raw.squeeze(2).unsqueeze(1) # (batch_size, 1, time_steps)\n",
    "        # apply softmax across the time_steps\n",
    "        weights = F.softmax(scores_raw, dim=-1) # (batch_size, 1, time_steps)\n",
    "\n",
    "        context = torch.bmm(weights, keys) # (batch_size, 1, time_steps) * (batch_size, time_steps, hidden_size) = (batch_size, 1, hidden_size)\n",
    "\n",
    "        # Another way to calculate the context vector\n",
    "        # element_wise_multiplication = keys * weights\n",
    "        # context_vector = torch.sum(element_wise_multiplication, dim=1, keepdim=True)\n",
    "\n",
    "        return context, weights\n",
    "\n",
    "\n",
    "\n",
    "class BhadanauAttentionBeforeOutputEncoderRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, dropout_p=0.1):\n",
    "        super(BhadanauAttentionBeforeOutputEncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # Convert to embedding {vocab_size, embedding_dimension: hidden_size}\n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, input):\n",
    "        # Embedding vector\n",
    "        embedding_vector = self.embedding(input)\n",
    "        embedding_vector = self.dropout(embedding_vector)\n",
    "\n",
    "        output, hidden = self.gru(embedding_vector)\n",
    "        return output, hidden\n",
    "\n",
    "class BhadanauAttentionBeforeOutputDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(BhadanauAttentionBeforeOutputDecoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "\n",
    "        # Attention layer\n",
    "        self.attention = BhadanauAttentionBeforeOutput(hidden_size)\n",
    "\n",
    "        # Inputs: ((word_embedding+context), hidden)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "\n",
    "        # Inputs: ((hidden+context+input_token))\n",
    "        self.out = nn.Linear(hidden_size + hidden_size, output_size)\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
    "\n",
    "        encoder_context_vector = encoder_hidden\n",
    "\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs = []\n",
    "        predicted_decoder_tokens = []\n",
    "        predicted_attn_weights = []\n",
    "\n",
    "        for i in range(MAX_LENGTH):\n",
    "#             print(f\"Input Shape before forward step: {decoder_input.shape}\")\n",
    "            decoder_output, decoder_hidden, attn_weights  = self.forward_step(decoder_input, decoder_hidden, encoder_context_vector, encoder_outputs)\n",
    "            decoder_outputs.append(decoder_output)\n",
    "            predicted_attn_weights.append(attn_weights)\n",
    "\n",
    "            if target_tensor is not None:\n",
    "                # Teacher forcing: Feed the target as the next input\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
    "            else:\n",
    "#                 print(\"Without teacher forcing\")\n",
    "                # Without teacher forcing: use its own predictions as the next input\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
    "                predicted_decoder_tokens.append(decoder_input)\n",
    "\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "        predicted_attn_weights = torch.cat(predicted_attn_weights, dim=1)\n",
    "        # decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)  # not needed since we are using cross entropy loss instead of NLL loss\n",
    "        return decoder_outputs, decoder_hidden, predicted_decoder_tokens, predicted_attn_weights # We return `None` for consistency in the training loop\n",
    "\n",
    "    def forward_step(self, input, prev_hidden_state, encoder_context_vector, encoder_outputs):\n",
    "\n",
    "        input_token_embedding = self.embedding(input)\n",
    "        input_token_embedding_relued = F.relu(input_token_embedding)\n",
    "\n",
    "        # Forward rnn cell pass\n",
    "        gru_output, gru_hidden = self.gru(input_token_embedding_relued, prev_hidden_state)\n",
    "\n",
    "        # Get Attention context for this time step using the encoder outputs and the current hidden state\n",
    "        query = gru_hidden.permute(1, 0, 2)\n",
    "        context, attn_weights = self.attention(encoder_outputs, query) # keys, query\n",
    "\n",
    "        context = context.permute(1, 0, 2)\n",
    "\n",
    "        # Concatenate the current hidden state and this time step's attended context\n",
    "        decoder_hidden_concatenate_attended_context = torch.cat(\n",
    "            (\n",
    "                gru_hidden,\n",
    "                context\n",
    "            ),\n",
    "            2\n",
    "        )\n",
    "\n",
    "        # Pass through the linear layer to get logits distribution on each output vocab word\n",
    "        linear_output = self.out(decoder_hidden_concatenate_attended_context)\n",
    "        # print(f\"linear_output shape before: {linear_output.shape}\")\n",
    "\n",
    "        # Another way to\n",
    "        # linear_output = linear_output.view(linear_output.shape[1], linear_output.shape[0], linear_output.shape[2])\n",
    "        linear_output = linear_output.permute(1,0,2)\n",
    "\n",
    "        return linear_output, gru_hidden, attn_weights\n",
    "\n",
    "class BhadanauAttentionBeforeOutputEncoderDecoderTranslation(nn.Module):\n",
    "\n",
    "    def __init__(self, input_lang, output_lang, hidden_size, device):\n",
    "        super(BhadanauAttentionBeforeOutputEncoderDecoderTranslation, self).__init__()\n",
    "\n",
    "        self.encoder = BhadanauAttentionBeforeOutputEncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "        self.decoder = BhadanauAttentionBeforeOutputDecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, input_tensor, target_tensor=None):\n",
    "\n",
    "        encoder_outputs, encoder_hidden = self.encoder(input_tensor)\n",
    "        decoder_outputs, _, predicted_decoder_tokens, predicted_attn_weights = self.decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
    "\n",
    "        return decoder_outputs, predicted_decoder_tokens, predicted_attn_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1706443645321,
     "user": {
      "displayName": "Vaibhav Bansal",
      "userId": "03259254199963156033"
     },
     "user_tz": -330
    },
    "id": "0riCRmL9v7Il"
   },
   "outputs": [],
   "source": [
    "def train_epoch(dataloader, encoder_decoder, encoder_decoder_optimizer, criterion):\n",
    "\n",
    "    total_loss = 0\n",
    "    for data in tqdm(dataloader):\n",
    "        input_tensor, target_tensor = data\n",
    "\n",
    "        # zero out gradients before each batch\n",
    "        encoder_decoder_optimizer.zero_grad()\n",
    "\n",
    "        # Run encoder-decoder forward()\n",
    "        decoder_outputs, _, _ = encoder_decoder(input_tensor, target_tensor)\n",
    "\n",
    "        # calculate loss\n",
    "        loss = criterion(\n",
    "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
    "            target_tensor.view(-1)\n",
    "        )\n",
    "\n",
    "        # calculate gradients\n",
    "        loss.backward()\n",
    "        # update weights\n",
    "        encoder_decoder_optimizer.step()\n",
    "\n",
    "        # update epoch level loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def normalize_tensors_to_tokens(tensor, remove_first_idx=False):\n",
    "\n",
    "  # convert_to_list\n",
    "  tensor = tensor.tolist()\n",
    "\n",
    "  # remove_sos_eos_and_pads_convert_list\n",
    "  if remove_first_idx:\n",
    "    tensor = [sequence[1:] for sequence in tensor]\n",
    "\n",
    "  # remove all tokens after <eos token>\n",
    "  out_list = []\n",
    "  for sequence in tensor:\n",
    "    new_seq = []\n",
    "    for token in sequence:\n",
    "      if token == EOS_token:\n",
    "        break\n",
    "      new_seq.append(token)\n",
    "    out_list.append(new_seq)\n",
    "\n",
    "  return out_list\n",
    "\n",
    "\n",
    "def predict(data_loader, encoder_decoder):\n",
    "\n",
    "  # Eval Mode. Turn off dropout and batchnorm\n",
    "  encoder_decoder.eval()\n",
    "\n",
    "  list_decoder_outputs = []\n",
    "\n",
    "  # ensure no gradients are calculated with no_grad() to preserve memory\n",
    "  with torch.no_grad():\n",
    "    for data in data_loader:\n",
    "      input_tensor, target_tensor = data\n",
    "      decoder_outputs, predicted_decoder_tokens, predicted_attn_weights = encoder_decoder(input_tensor)\n",
    "      list_decoder_outputs.append(decoder_outputs)\n",
    "\n",
    "      # Merge timesteps of decoder predictions\n",
    "      predicted_decoder_tokens = torch.cat(predicted_decoder_tokens, dim=1)\n",
    "\n",
    "  return list_decoder_outputs, input_tensor, target_tensor, predicted_decoder_tokens, predicted_attn_weights\n",
    "\n",
    "\n",
    "def calculate_bleu(test_target_tokens, predicted_decoder_tokens):\n",
    "\n",
    "  return corpus_bleu(\n",
    "      [[item] for item in test_target_tokens],\n",
    "      [item for item in predicted_decoder_tokens],\n",
    "    )\n",
    "\n",
    "def train(train_dataloader, test_dataloader, encoder_decoder, n_epochs, learning_rate=0.001,\n",
    "               print_every=100, plot_every=100):\n",
    "\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_decoder_optimizer = optim.Adam(encoder_decoder.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Ignore pad token from loss calculation\n",
    "    if is_ignore_pads:\n",
    "      # criterion = nn.NLLLoss(ignore_index = PAD_token)\n",
    "      criterion = nn.CrossEntropyLoss(ignore_index = PAD_token)\n",
    "    else:\n",
    "      criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    print('Time \\t\\t\\t (Epoch\\t%) \\t Loss \\t\\t Bleu')\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        # Training\n",
    "        encoder_decoder.train()\n",
    "        loss = train_epoch(train_dataloader, encoder_decoder, encoder_decoder_optimizer, criterion)\n",
    "\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        # Eval on Test\n",
    "        encoder_decoder.eval()\n",
    "        # Evaluate without teacher forcing on test set\n",
    "        test_list_decoder_outputs, test_input_tensor, test_target_tensor, predicted_decoder_tokens, _ = predict(test_dataloader, encoder_decoder)\n",
    "\n",
    "        # Calculate bleu\n",
    "        bleu = calculate_bleu(\n",
    "            normalize_tensors_to_tokens(test_target_tensor, False),\n",
    "            normalize_tensors_to_tokens(predicted_decoder_tokens, False)\n",
    "        )\n",
    "\n",
    "\n",
    "        if epoch % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s \\t (%d \\t %d%%) \\t %.4f \\t %.4f' % (Helpers.timeSince(start, epoch / n_epochs),\n",
    "                                        epoch, epoch / n_epochs * 100, print_loss_avg, bleu))\n",
    "\n",
    "        if epoch % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    Helpers.showPlot(plot_losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1219053,
     "status": "error",
     "timestamp": 1706444864370,
     "user": {
      "displayName": "Vaibhav Bansal",
      "userId": "03259254199963156033"
     },
     "user_tz": -330
    },
    "id": "r4NY1Q_Kq77W",
    "outputId": "f2f269dd-58b1-4da6-d1a8-f155480e8d84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 135842 sentence pairs\n",
      "Trimmed to 105692 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "fra 17865\n",
      "eng 10699\n",
      "Train and Test Dataset # samples: 100407, 5285\n",
      "Train and Test Dataloader # batches: 99, 1\n",
      "Time \t\t\t (Epoch\t%) \t Loss \t\t Bleu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:12<00:00,  7.72it/s]\n",
      "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "100%|██████████| 99/99 [00:11<00:00,  8.78it/s]\n",
      "100%|██████████| 99/99 [00:10<00:00,  9.07it/s]\n",
      "100%|██████████| 99/99 [00:11<00:00,  8.39it/s]\n",
      "100%|██████████| 99/99 [00:11<00:00,  8.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 3s (- 41m 8s) \t (5 \t 2%) \t 3.8746 \t 0.1904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:11<00:00,  8.48it/s]\n",
      "100%|██████████| 99/99 [00:11<00:00,  8.52it/s]\n",
      "100%|██████████| 99/99 [00:12<00:00,  8.22it/s]\n",
      "100%|██████████| 99/99 [00:12<00:00,  8.22it/s]\n",
      "100%|██████████| 99/99 [00:11<00:00,  8.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2m 6s (- 40m 4s) \t (10 \t 5%) \t 1.8292 \t 0.3423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:11<00:00,  8.40it/s]\n",
      "100%|██████████| 99/99 [00:11<00:00,  8.45it/s]\n",
      "100%|██████████| 99/99 [00:11<00:00,  8.44it/s]\n",
      "100%|██████████| 99/99 [00:11<00:00,  8.40it/s]\n",
      "100%|██████████| 99/99 [00:11<00:00,  8.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3m 8s (- 38m 48s) \t (15 \t 7%) \t 1.2594 \t 0.4043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:11<00:00,  8.36it/s]\n",
      "100%|██████████| 99/99 [00:11<00:00,  8.40it/s]\n",
      "100%|██████████| 99/99 [00:11<00:00,  8.43it/s]\n",
      "100%|██████████| 99/99 [00:11<00:00,  8.40it/s]\n",
      "100%|██████████| 99/99 [00:11<00:00,  8.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4m 11s (- 37m 46s) \t (20 \t 10%) \t 0.9839 \t 0.4414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:11<00:00,  8.36it/s]\n",
      "100%|██████████| 99/99 [00:11<00:00,  8.42it/s]\n",
      "100%|██████████| 99/99 [00:11<00:00,  8.39it/s]\n",
      "100%|██████████| 99/99 [00:11<00:00,  8.37it/s]\n",
      "100%|██████████| 99/99 [00:11<00:00,  8.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5m 14s (- 36m 43s) \t (25 \t 12%) \t 0.8209 \t 0.4635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:11<00:00,  8.43it/s]\n",
      "100%|██████████| 99/99 [00:11<00:00,  8.42it/s]\n",
      "100%|██████████| 99/99 [00:11<00:00,  8.40it/s]\n",
      "100%|██████████| 99/99 [00:11<00:00,  8.39it/s]\n",
      "100%|██████████| 99/99 [00:11<00:00,  8.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6m 17s (- 35m 37s) \t (30 \t 15%) \t 0.7085 \t 0.4781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:11<00:00,  8.40it/s]\n",
      "100%|██████████| 99/99 [00:11<00:00,  8.32it/s]\n",
      "100%|██████████| 99/99 [00:11<00:00,  8.31it/s]\n",
      "100%|██████████| 99/99 [00:11<00:00,  8.38it/s]\n",
      "100%|██████████| 99/99 [00:11<00:00,  8.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7m 20s (- 34m 35s) \t (35 \t 17%) \t 0.6242 \t 0.4880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:11<00:00,  8.40it/s]\n",
      "100%|██████████| 99/99 [00:11<00:00,  8.49it/s]\n",
      "100%|██████████| 99/99 [00:11<00:00,  8.27it/s]\n",
      "100%|██████████| 99/99 [00:11<00:00,  8.43it/s]\n",
      "100%|██████████| 99/99 [00:11<00:00,  8.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8m 22s (- 33m 30s) \t (40 \t 20%) \t 0.5577 \t 0.4923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:11<00:00,  8.41it/s]\n",
      "100%|██████████| 99/99 [00:11<00:00,  8.33it/s]\n",
      "100%|██████████| 99/99 [00:11<00:00,  8.25it/s]\n",
      "100%|██████████| 99/99 [00:11<00:00,  8.39it/s]\n",
      "100%|██████████| 99/99 [00:11<00:00,  8.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9m 25s (- 32m 27s) \t (45 \t 22%) \t 0.5050 \t 0.4936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:11<00:00,  8.42it/s]\n",
      "100%|██████████| 99/99 [00:11<00:00,  8.41it/s]\n",
      "100%|██████████| 99/99 [00:11<00:00,  8.42it/s]\n",
      "100%|██████████| 99/99 [00:11<00:00,  8.38it/s]\n",
      "100%|██████████| 99/99 [00:11<00:00,  8.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10m 27s (- 31m 23s) \t (50 \t 25%) \t 0.4628 \t 0.4993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:11<00:00,  8.40it/s]\n",
      "100%|██████████| 99/99 [00:11<00:00,  8.30it/s]\n",
      "100%|██████████| 99/99 [00:11<00:00,  8.44it/s]\n",
      "100%|██████████| 99/99 [00:11<00:00,  8.47it/s]\n",
      "100%|██████████| 99/99 [00:11<00:00,  8.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11m 31s (- 30m 22s) \t (55 \t 27%) \t 0.4245 \t 0.5130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:11<00:00,  8.43it/s]\n",
      "100%|██████████| 99/99 [00:11<00:00,  8.33it/s]\n",
      "100%|██████████| 99/99 [00:11<00:00,  8.45it/s]\n",
      "100%|██████████| 99/99 [00:11<00:00,  8.40it/s]\n",
      "100%|██████████| 99/99 [00:11<00:00,  8.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12m 34s (- 29m 20s) \t (60 \t 30%) \t 0.3929 \t 0.5158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:11<00:00,  8.32it/s]\n",
      "100%|██████████| 99/99 [00:11<00:00,  8.44it/s]\n",
      "100%|██████████| 99/99 [00:11<00:00,  8.41it/s]\n",
      "100%|██████████| 99/99 [00:11<00:00,  8.43it/s]\n",
      "100%|██████████| 99/99 [00:11<00:00,  8.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13m 37s (- 28m 18s) \t (65 \t 32%) \t 0.3649 \t 0.5291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:11<00:00,  8.27it/s]\n",
      "100%|██████████| 99/99 [00:11<00:00,  8.55it/s]\n",
      "100%|██████████| 99/99 [00:11<00:00,  8.44it/s]\n",
      "100%|██████████| 99/99 [00:11<00:00,  8.45it/s]\n",
      "100%|██████████| 99/99 [00:11<00:00,  8.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14m 41s (- 27m 17s) \t (70 \t 35%) \t 0.3422 \t 0.5222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:11<00:00,  8.33it/s]\n",
      "100%|██████████| 99/99 [00:11<00:00,  8.44it/s]\n",
      "100%|██████████| 99/99 [00:11<00:00,  8.44it/s]\n",
      "100%|██████████| 99/99 [00:11<00:00,  8.39it/s]\n",
      "100%|██████████| 99/99 [00:11<00:00,  8.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15m 44s (- 26m 13s) \t (75 \t 37%) \t 0.3187 \t 0.5284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:11<00:00,  8.42it/s]\n",
      "100%|██████████| 99/99 [00:11<00:00,  8.45it/s]\n",
      "100%|██████████| 99/99 [00:11<00:00,  8.35it/s]\n",
      "100%|██████████| 99/99 [00:11<00:00,  8.53it/s]\n",
      "100%|██████████| 99/99 [00:11<00:00,  8.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16m 46s (- 25m 9s) \t (80 \t 40%) \t 0.3002 \t 0.5329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:11<00:00,  8.41it/s]\n",
      "100%|██████████| 99/99 [00:11<00:00,  8.41it/s]\n",
      "100%|██████████| 99/99 [00:11<00:00,  8.43it/s]\n",
      "100%|██████████| 99/99 [00:11<00:00,  8.35it/s]\n",
      "100%|██████████| 99/99 [00:11<00:00,  8.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17m 48s (- 24m 5s) \t (85 \t 42%) \t 0.2830 \t 0.5378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:11<00:00,  8.44it/s]\n",
      "100%|██████████| 99/99 [00:11<00:00,  8.53it/s]\n",
      "100%|██████████| 99/99 [00:11<00:00,  8.44it/s]\n",
      "100%|██████████| 99/99 [00:11<00:00,  8.30it/s]\n",
      "100%|██████████| 99/99 [00:11<00:00,  8.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18m 51s (- 23m 2s) \t (90 \t 45%) \t 0.2684 \t 0.5381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:11<00:00,  8.53it/s]\n",
      "100%|██████████| 99/99 [00:11<00:00,  8.43it/s]\n",
      "100%|██████████| 99/99 [00:11<00:00,  8.44it/s]\n",
      "100%|██████████| 99/99 [00:11<00:00,  8.32it/s]\n",
      "100%|██████████| 99/99 [00:11<00:00,  8.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19m 53s (- 21m 59s) \t (95 \t 47%) \t 0.2546 \t 0.5345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:11<00:00,  8.39it/s]\n",
      " 65%|██████▍   | 64/99 [00:07<00:04,  8.32it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-dd438b895a87>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mencoder_decoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBhadanauAttentionBeforeOutputEncoderDecoderTranslation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_lang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_lang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_decoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-17708846eae7>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_dataloader, test_dataloader, encoder_decoder, n_epochs, learning_rate, print_every, plot_every)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;31m# Training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mencoder_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_decoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_decoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mprint_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-17708846eae7>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(dataloader, encoder_decoder, encoder_decoder_optimizer, criterion)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Handle `CustomType` automatically\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \"\"\"\n\u001b[0;32m--> 265\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_collate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcollate_fn_map\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0melem_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcollate_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate_tensor_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_typed_storage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "is_ignore_pads = True\n",
    "input_lang, output_lang, train_dataloader, test_dataloader = DataLoaderHandler.get_dataloader(batch_size)\n",
    "\n",
    "# init encoder-decoder\n",
    "encoder_decoder = BhadanauAttentionBeforeOutputEncoderDecoderTranslation(input_lang, output_lang, hidden_size, device)\n",
    "\n",
    "train(train_dataloader, test_dataloader, encoder_decoder, epochs, print_every=5, plot_every=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "aborted",
     "timestamp": 1706444864370,
     "user": {
      "displayName": "Vaibhav Bansal",
      "userId": "03259254199963156033"
     },
     "user_tz": -330
    },
    "id": "J4vi8p0O8Tui"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def show_model_layers_and_params(model):\n",
    "    print(\"Model Layers:\")\n",
    "    print(\"--------------\")\n",
    "    for name, module in model.named_children():\n",
    "        print(f\"{name}: {module}\")\n",
    "\n",
    "    print(\"\\nLayer-wise Number of Parameters and Memory Requirements:\")\n",
    "    print(\"-------------------------------------------------------\")\n",
    "    total_params = 0\n",
    "    total_memory = 0\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            num_params = param.numel()\n",
    "            param_memory = num_params * param.element_size() / (1024 ** 2)  # Memory in MBs\n",
    "            print(f\"{name}: {num_params} parameters, {param_memory:.2f} MB\")\n",
    "            total_params += num_params\n",
    "            total_memory += param_memory\n",
    "\n",
    "    print(\"\\nTotal Number of Parameters and Memory Usage:\")\n",
    "    print(\"------------------------------------------\")\n",
    "    print(f\"Total parameters: {total_params}\")\n",
    "    print(f\"Total memory usage: {total_memory:.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "aborted",
     "timestamp": 1706444864370,
     "user": {
      "displayName": "Vaibhav Bansal",
      "userId": "03259254199963156033"
     },
     "user_tz": -330
    },
    "id": "mQBWv-ea3hK9"
   },
   "outputs": [],
   "source": [
    "show_model_layers_and_params(encoder_decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P5sWS7dw3km-"
   },
   "source": [
    "- Does dot product attention increase the number of params?\n",
    "- Visualize Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "aborted",
     "timestamp": 1706444864371,
     "user": {
      "displayName": "Vaibhav Bansal",
      "userId": "03259254199963156033"
     },
     "user_tz": -330
    },
    "id": "HF3AUb9mmgW2"
   },
   "outputs": [],
   "source": [
    "# Predict\n",
    "test_list_decoder_outputs, test_input_tensor, test_target_tensor, predicted_decoder_tokens, predicted_attn_weights = predict(test_dataloader, encoder_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "aborted",
     "timestamp": 1706444864371,
     "user": {
      "displayName": "Vaibhav Bansal",
      "userId": "03259254199963156033"
     },
     "user_tz": -330
    },
    "id": "3MjYBvJQUckH"
   },
   "outputs": [],
   "source": [
    "# Example Predictions without normalizing tokens\n",
    "print(DataLoaderHandler.sentenceFromIndices(input_lang, test_input_tensor[0].tolist()))\n",
    "print(DataLoaderHandler.sentenceFromIndices(output_lang, test_target_tensor[0].tolist()))\n",
    "print(DataLoaderHandler.sentenceFromIndices(output_lang, predicted_decoder_tokens[0].tolist()))\n",
    "print()\n",
    "print(DataLoaderHandler.sentenceFromIndices(input_lang, test_input_tensor[1].tolist()))\n",
    "print(DataLoaderHandler.sentenceFromIndices(output_lang, test_target_tensor[1].tolist()))\n",
    "print(DataLoaderHandler.sentenceFromIndices(output_lang, predicted_decoder_tokens[1].tolist()))\n",
    "print()\n",
    "print(DataLoaderHandler.sentenceFromIndices(input_lang, test_input_tensor[2].tolist()))\n",
    "print(DataLoaderHandler.sentenceFromIndices(output_lang, test_target_tensor[2].tolist()))\n",
    "print(DataLoaderHandler.sentenceFromIndices(output_lang, predicted_decoder_tokens[2].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "aborted",
     "timestamp": 1706444864371,
     "user": {
      "displayName": "Vaibhav Bansal",
      "userId": "03259254199963156033"
     },
     "user_tz": -330
    },
    "id": "llYgWdxhRQHW"
   },
   "outputs": [],
   "source": [
    "# Normalize tokens\n",
    "test_input_tensor = normalize_tensors_to_tokens(test_input_tensor, False)\n",
    "test_target_tensor = normalize_tensors_to_tokens(test_target_tensor, False)\n",
    "predicted_decoder_tokens = normalize_tensors_to_tokens(predicted_decoder_tokens, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "aborted",
     "timestamp": 1706444864371,
     "user": {
      "displayName": "Vaibhav Bansal",
      "userId": "03259254199963156033"
     },
     "user_tz": -330
    },
    "id": "njMlc4YempAE"
   },
   "outputs": [],
   "source": [
    "# Example Predictions with normalizing tokens\n",
    "print(DataLoaderHandler.sentenceFromIndices(input_lang, test_input_tensor[0]))\n",
    "print(DataLoaderHandler.sentenceFromIndices(output_lang, test_target_tensor[0]))\n",
    "print(DataLoaderHandler.sentenceFromIndices(output_lang, predicted_decoder_tokens[0]))\n",
    "print()\n",
    "print(DataLoaderHandler.sentenceFromIndices(input_lang, test_input_tensor[1]))\n",
    "print(DataLoaderHandler.sentenceFromIndices(output_lang, test_target_tensor[1]))\n",
    "print(DataLoaderHandler.sentenceFromIndices(output_lang, predicted_decoder_tokens[1]))\n",
    "print()\n",
    "print(DataLoaderHandler.sentenceFromIndices(input_lang, test_input_tensor[2]))\n",
    "print(DataLoaderHandler.sentenceFromIndices(output_lang, test_target_tensor[2]))\n",
    "print(DataLoaderHandler.sentenceFromIndices(output_lang, predicted_decoder_tokens[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "aborted",
     "timestamp": 1706444864371,
     "user": {
      "displayName": "Vaibhav Bansal",
      "userId": "03259254199963156033"
     },
     "user_tz": -330
    },
    "id": "yxC2OUPTNG0l"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "aborted",
     "timestamp": 1706444864372,
     "user": {
      "displayName": "Vaibhav Bansal",
      "userId": "03259254199963156033"
     },
     "user_tz": -330
    },
    "id": "zGgMvtMrNjL4"
   },
   "outputs": [],
   "source": [
    "def showAttention(input_words, output_words, attentions):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.cpu().numpy(), cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set up axes\n",
    "    # ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
    "    #                    ['<EOS>'], rotation=90)\n",
    "    ax.set_xticklabels([''] + input_words, rotation=30)\n",
    "    ax.set_yticklabels([''] + output_words, rotation=30)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "\n",
    "def visualize_attentions(idx, test_input_tensor, test_target_tensor, predicted_decoder_tokens, predicted_attn_weights, input_lang, output_lang):\n",
    "\n",
    "\n",
    "    input_lang_tokens = DataLoaderHandler.outputLangTokensFromIndices(input_lang, test_input_tensor[idx].tolist())\n",
    "    target_lang_tokens = DataLoaderHandler.outputLangTokensFromIndices(output_lang, test_target_tensor[idx].tolist())\n",
    "    predicted_lang_tokens = DataLoaderHandler.outputLangTokensFromIndices(output_lang, predicted_decoder_tokens[idx].tolist())\n",
    "    attentions = predicted_attn_weights[idx]\n",
    "\n",
    "    print(input_lang_tokens)\n",
    "    print(target_lang_tokens)\n",
    "    print(predicted_lang_tokens)\n",
    "\n",
    "    showAttention(input_lang_tokens, predicted_lang_tokens, attentions)\n",
    "\n",
    "\n",
    "test_list_decoder_outputs, test_input_tensor, test_target_tensor, predicted_decoder_tokens, predicted_attn_weights = predict(test_dataloader, encoder_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "aborted",
     "timestamp": 1706444864372,
     "user": {
      "displayName": "Vaibhav Bansal",
      "userId": "03259254199963156033"
     },
     "user_tz": -330
    },
    "id": "PD2vvUMWeeyH"
   },
   "outputs": [],
   "source": [
    "visualize_attentions(1, test_input_tensor, test_target_tensor, predicted_decoder_tokens, predicted_attn_weights, input_lang, output_lang)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wMGHE5HRqWgz"
   },
   "source": [
    "# TO TRY\n",
    "- Ignore padding token loss (ignore index) - mixed results\n",
    "- evaluation metric - bleu (done)\n",
    "- EOS token related sequence clipping - done\n",
    "- shifted target sequence? - ignore (done)\n",
    "- loss: what all to include? to include <EOS>? - eos included, padding not included\n",
    "- Output Vocab is a big choking point {among other things} that can prevent large gpu batches since we have to store the output vectors of shape (batch_size, time_steps, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "aborted",
     "timestamp": 1706444864372,
     "user": {
      "displayName": "Vaibhav Bansal",
      "userId": "03259254199963156033"
     },
     "user_tz": -330
    },
    "id": "uS7KdW3zDTQO"
   },
   "outputs": [],
   "source": [
    "# def train_epoch(dataloader, encoder, decoder, encoder_optimizer,\n",
    "#           decoder_optimizer, criterion):\n",
    "\n",
    "#     total_loss = 0\n",
    "#     for data in dataloader:\n",
    "#         input_tensor, target_tensor = data\n",
    "\n",
    "#         encoder_optimizer.zero_grad()\n",
    "#         decoder_optimizer.zero_grad()\n",
    "\n",
    "#         encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "#         decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
    "\n",
    "#         loss = criterion(\n",
    "#             decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
    "#             target_tensor.view(-1)\n",
    "#         )\n",
    "#         loss.backward()\n",
    "\n",
    "#         encoder_optimizer.step()\n",
    "#         decoder_optimizer.step()\n",
    "\n",
    "#         total_loss += loss.item()\n",
    "\n",
    "#     return total_loss / len(dataloader)\n",
    "\n",
    "# def train(train_dataloader, encoder, decoder, n_epochs, learning_rate=0.001,\n",
    "#                print_every=100, plot_every=100):\n",
    "#     start = time.time()\n",
    "#     plot_losses = []\n",
    "#     print_loss_total = 0  # Reset every print_every\n",
    "#     plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "#     encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "#     decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "#     criterion = nn.NLLLoss()\n",
    "\n",
    "#     for epoch in range(1, n_epochs + 1):\n",
    "#         loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "#         print_loss_total += loss\n",
    "#         plot_loss_total += loss\n",
    "\n",
    "#         if epoch % print_every == 0:\n",
    "#             print_loss_avg = print_loss_total / print_every\n",
    "#             print_loss_total = 0\n",
    "#             print('%s (%d %d%%) %.4f' % (Helpers.timeSince(start, epoch / n_epochs),\n",
    "#                                         epoch, epoch / n_epochs * 100, print_loss_avg))\n",
    "\n",
    "#         if epoch % plot_every == 0:\n",
    "#             plot_loss_avg = plot_loss_total / plot_every\n",
    "#             plot_losses.append(plot_loss_avg)\n",
    "#             plot_loss_total = 0\n",
    "\n",
    "#     Helpers.showPlot(plot_losses)\n",
    "\n",
    "# hidden_size = 128\n",
    "# batch_size = 32\n",
    "# input_lang, output_lang, train_dataloader = DataLoaderHandler.get_dataloader(batch_size)\n",
    "# encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "# decoder = DecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
    "\n",
    "# # train(train_dataloader, encoder, decoder, 80, print_every=5, plot_every=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "aborted",
     "timestamp": 1706444864372,
     "user": {
      "displayName": "Vaibhav Bansal",
      "userId": "03259254199963156033"
     },
     "user_tz": -330
    },
    "id": "5QpTo7s10fgp"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data for the x-axis and y-axis\n",
    "x_values = [1, 2, 3, 4, 5]\n",
    "y_values = [2, 4, 6, 8, 10]\n",
    "\n",
    "# Plotting the line\n",
    "plt.plot(x_values, y_values, marker='o', linestyle='-')  # 'o' for markers, '-' for line style\n",
    "plt.title('Simple Line Plot')\n",
    "plt.xlabel('X-axis')\n",
    "plt.ylabel('Y-axis')\n",
    "plt.grid(True)  # Show grid\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "aborted",
     "timestamp": 1706444864372,
     "user": {
      "displayName": "Vaibhav Bansal",
      "userId": "03259254199963156033"
     },
     "user_tz": -330
    },
    "id": "mpb9O8LAFHF2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOkdaFCSMResch7QNV2/Dcd",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
