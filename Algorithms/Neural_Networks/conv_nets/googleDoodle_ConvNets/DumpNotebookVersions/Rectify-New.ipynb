{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "import re\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, _imaging\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "from keras.callbacks import History, ModelCheckpoint\n",
    "history = History()\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showSampleImgs():\n",
    "    n_samp = 3\n",
    "    train_df_sample = train_df.sample(n_samp)\n",
    "    plt.figure(figsize=(4,4))\n",
    "    for i in range(n_samp):\n",
    "        draw = train_df_sample.iloc[i]['drawing']\n",
    "        label = train_df_sample.iloc[i]['word']\n",
    "        plt.subplot(n_samp,1,i+1)\n",
    "        for stroke in draw:\n",
    "            plt.plot(stroke[0], stroke[1], marker='.', color='black')\n",
    "            plt.title(label)\n",
    "            plt.axis('off')\n",
    "    plt.show()    \n",
    "    \n",
    "# Show an image from the dataframe\n",
    "def showImgFromDf(df, index):\n",
    "    # Show an image\n",
    "    plt.imshow(df.iloc[index]['img'],cmap='gray')\n",
    "    plt.title(df.iloc[index]['word'])\n",
    "    plt.show()\n",
    "    \n",
    "def top_3_accuracy(y_true, y_pred):\n",
    "    return metrics.top_k_categorical_accuracy(y_true, y_pred, k=3)\n",
    "\n",
    "\n",
    "def baseline_conv_model(num_filters, num_classes, img_height, img_width):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(num_filters*1, (5,5), input_shape=(img_height,img_width,1), activation='relu')) \n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(num_filters*2, (5,5), activation='relu')) \n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(num_filters*4, (3,3), activation='relu')) \n",
    "#     model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#     model.add(Conv2D(num_filters*8, (3,3), activation='relu')) \n",
    "#     model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1000, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(500, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "#     model.add(Dense(500, activation='relu'))\n",
    "#     model.add(Dropout(0.2))\n",
    "#     model.add(Dense(1000, activation='relu'))\n",
    "#     model.add(Dropout(0.2))\n",
    "    # model.add(Dense(num_classes, activation='softmax'))\n",
    "    # model.add(Activation('softmax'))\n",
    "    model.add(Dense(units=num_classes))\n",
    "    model.add(Activation(tf.nn.softmax))\n",
    "\n",
    "    # Compile\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', top_3_accuracy, 'categorical_crossentropy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(111)\n",
    "\n",
    "# Generate class mappings\n",
    "fnames = glob('train_sample/*.csv')\n",
    "tempDf = pd.DataFrame(columns=pd.read_csv(fnames[0], nrows=1).columns)\n",
    "\n",
    "for name in fnames:\n",
    "    data = pd.read_csv(name, nrows=2)\n",
    "    tempDf = tempDf.append(data)\n",
    "    \n",
    "ys = tempDf['word']\n",
    "    \n",
    "# Convert class labels from categorical to numerical\n",
    "unique_classes_list = ys.unique()\n",
    "map_class_to_numeric = {k: v for v, k in enumerate(unique_classes_list)}\n",
    "map_numeric_to_class = {v: k for k, v in map_class_to_numeric.iteritems()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1904"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5000/340 * 136"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_it(raw_strokes, output_height, output_width):\n",
    "    raw_strokes = eval(raw_strokes)\n",
    "    image = Image.new(\"P\", (255,255)\n",
    "#                       , color=1\n",
    "            )\n",
    "    image_draw = ImageDraw.Draw(image)\n",
    "\n",
    "    for stroke in raw_strokes:\n",
    "        for i in range(len(stroke[0])-1):\n",
    "\n",
    "            image_draw.line([stroke[0][i], \n",
    "                             stroke[1][i],\n",
    "                             stroke[0][i+1], \n",
    "                             stroke[1][i+1]],\n",
    "                            fill=255, width=6)\n",
    "    # Reduce image size\n",
    "    image = image.resize((output_height,output_width),Image.ANTIALIAS)\n",
    "    \n",
    "    return np.array(image)\n",
    "\n",
    "\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, num_samples_to_train, batch_size, img_width, img_height):\n",
    "        self.batch_size = batch_size\n",
    "        self.num_samples_to_train = num_samples_to_train\n",
    "        self.img_width = img_width\n",
    "        self.img_height = img_height    \n",
    "    def __len__(self):\n",
    "        return np.ceil(self.num_samples_to_train / float(self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        numRowsEachDf = int(self.batch_size / float(numClasses))\n",
    "        skipRows = (idx * numRowsEachDf)\n",
    "        img_height = self.img_height \n",
    "        img_width = self.img_width\n",
    "        \n",
    "        X, y = DataGenerator._getNextData(numRowsEachDf, skipRows, img_height, img_width)\n",
    "        \n",
    "        return X, y\n",
    "\n",
    "    @staticmethod\n",
    "    def _getNextData(numRowsEachDf, skipRows, img_height, img_width):\n",
    "        \n",
    "        fnames = glob('train_sample/*.csv')\n",
    "        numClasses = len(fnames)\n",
    "\n",
    "        # Get n rows from all the csv files and append them into one dataframe\n",
    "        train_df = pd.DataFrame(columns=pd.read_csv(fnames[0], nrows=1).columns)\n",
    "        \n",
    "        for name in fnames:\n",
    "            if skipRows == 0:\n",
    "                data = pd.read_csv(name, nrows=numRowsEachDf)\n",
    "            else:\n",
    "                data = pd.read_csv(name, nrows=numRowsEachDf, skiprows=range(1,skipRows)) # 0th row is the header, so not skipping that\n",
    "            # Append the training data of all the classes\n",
    "            train_df = train_df.append(data)\n",
    "            \n",
    "        train_df = train_df.reset_index().drop('index', axis=1)\n",
    "        \n",
    "        # Get only those which were correctly recognized\n",
    "        train_df = train_df[train_df['recognized'] == True]\n",
    "        \n",
    "        # Convert drawing to images\n",
    "        train_df['drawing'] = train_df['drawing'].apply(lambda x: draw_it(x, img_height, img_width))\n",
    "\n",
    "        # Shuffle all data points\n",
    "        train_df = train_df.sample(train_df.shape[0])\n",
    "        \n",
    "            # Reshape the array\n",
    "        train_imgArr = np.vstack(train_df['drawing'].values).flatten().reshape((train_df['drawing'].shape[0], img_height, img_width))\n",
    "    \n",
    "        # In Keras, the layers used for two-dimensional convolutions expect pixel values with the dimensions [width][height][pixels] for TF.\n",
    "        # In the case of RGB, the first dimension pixels would be 3 for the red, green and blue components and it would be like having 3 image inputs for every color image. In this case, the pixel values are gray scale, the pixel dimension is set to 1.\n",
    "        train_X = train_imgArr.reshape(train_imgArr.shape[0], img_height, img_width, 1).astype('float32')\n",
    "        \n",
    "        \n",
    "         # Initialize the y_train\n",
    "        y_train = train_df['word']\n",
    "    \n",
    "        y_train_numeric = y_train.apply(lambda x: map_class_to_numeric[x])\n",
    "\n",
    "        # convert class vectors to binary class matrices\n",
    "        train_y = keras.utils.to_categorical(y_train_numeric, numClasses)\n",
    "        \n",
    "        return train_X, train_y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pp = []\n",
    "batch_size = 5*340\n",
    "numTrainExamplesPerClass = 50\n",
    "numClasses = 340\n",
    "num_samples_to_train = (numTrainExamplesPerClass*numClasses)\n",
    "img_width = img_height = 32\n",
    "dataGenerator = DataGenerator(num_samples_to_train, batch_size, img_width, img_height)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_width = img_height = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Gat static validation set\n",
    "# X_test, y_test = DataGenerator._getNextData(5, 90000, img_height, img_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_73 (Conv2D)           (None, 28, 28, 8)         208       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_49 (MaxPooling (None, 14, 14, 8)         0         \n",
      "_________________________________________________________________\n",
      "dropout_97 (Dropout)         (None, 14, 14, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_74 (Conv2D)           (None, 10, 10, 16)        3216      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_50 (MaxPooling (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "dropout_98 (Dropout)         (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_75 (Conv2D)           (None, 3, 3, 32)          4640      \n",
      "_________________________________________________________________\n",
      "flatten_25 (Flatten)         (None, 288)               0         \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 1000)              289000    \n",
      "_________________________________________________________________\n",
      "dropout_99 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "dropout_100 (Dropout)        (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 340)               170340    \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 340)               0         \n",
      "=================================================================\n",
      "Total params: 967,904\n",
      "Trainable params: 967,904\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "a must be greater than 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-222-d72817bb937c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;31m#     ,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m#         validation_data=(X_test, y_test)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/keras/engine/training_generator.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/keras/utils/data_utils.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m             \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/keras/utils/data_utils.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@2/2.7.15_1/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    570\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: a must be greater than 0"
     ]
    }
   ],
   "source": [
    "# # pp = []\n",
    "# batch_size = 15000\n",
    "# numTrainExamplesPerClass = 20000*340\n",
    "# numClasses = 340\n",
    "# num_samples_to_train = (numTrainExamplesPerClass*numClasses)\n",
    "# dataGenerator = DataGenerator(num_samples_to_train, batch_size, img_width, img_height)\n",
    "\n",
    "\n",
    "# model = baseline_conv_model(4, 340, 32, 32)\n",
    "numStartFilters = 8\n",
    "model = baseline_conv_model(numStartFilters, numClasses, img_height, img_width)\n",
    "print(model.summary())\n",
    "model.fit_generator(\n",
    "        generator=dataGenerator,\n",
    "        epochs=100,\n",
    "        verbose=2,\n",
    "        shuffle=False\n",
    "#     ,\n",
    "#         validation_data=(X_test, y_test)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pp[1]['X'].shape\n",
    "# qq[1]['X'].shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pp[0]['X'].shape\n",
    "# pp[0]['y'][96]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateTrainData(output_height, output_width, recordsPerTrainClass, skiprows=0):\n",
    "\n",
    "#     test_df = pd.read_csv('test_simplified.csv')\n",
    "\n",
    "    # Get names of all train csv files with the pattern match below\n",
    "    fnames = glob('train_sample/*.csv')\n",
    "\n",
    "    rows = recordsPerTrainClass\n",
    "    # Get n rows from all the csv files and append them into one dataframe\n",
    "    train_df = pd.DataFrame(columns=pd.read_csv(fnames[0], nrows=1).columns)\n",
    "    for name in fnames:\n",
    "        if skiprows == 0:\n",
    "            data = pd.read_csv(name, nrows=recordsPerTrainClass)\n",
    "        else:\n",
    "            data = pd.read_csv(name, nrows=recordsPerTrainClass, skiprows=range(1,skiprows))\n",
    "        train_df = train_df.append(data)\n",
    "\n",
    "#     print(train_df.shape)\n",
    "        \n",
    "    train_df = train_df.reset_index().drop('index', axis=1)\n",
    "    # Get only those which were correctly recognized\n",
    "    train_df = train_df[train_df['recognized'] == True]\n",
    "    \n",
    "    # Convert the drawing column to matrix\n",
    "#     train_df['drawing'] = train_df['drawing'].apply(ast.literal_eval)\n",
    "#     test_df['drawing'] = test_df['drawing'].apply(ast.literal_eval)\n",
    "    train_df['drawing'] = train_df['drawing'].apply(eval)\n",
    "#     test_df['drawing'] = test_df['drawing'].apply(eval)\n",
    "\n",
    "    # Convert drawing to images\n",
    "    train_df['img'] = train_df['drawing'].apply(lambda x: draw_it(x, output_height, output_width))\n",
    "#     test_df['img'] = test_df['drawing'].apply(lambda x: draw_it(x, output_height, output_width))\n",
    "    # train_df['img'] = train_df[['drawing']].apply(lambda x: draw_it(x['drawing'], output_height, output_width), axis=1)\n",
    "    # test_df['img'] = test_df[['drawing']].apply(lambda x: draw_it(x['drawing'], output_height, output_width), axis=1)\n",
    "    \n",
    "    return train_df, 'test_df'\n",
    "    \n",
    "def showSampleImgs():\n",
    "    n_samp = 3\n",
    "    train_df_sample = train_df.sample(n_samp)\n",
    "    plt.figure(figsize=(4,4))\n",
    "    for i in range(n_samp):\n",
    "        draw = train_df_sample.iloc[i]['drawing']\n",
    "        label = train_df_sample.iloc[i]['word']\n",
    "        plt.subplot(n_samp,1,i+1)\n",
    "        for stroke in draw:\n",
    "            plt.plot(stroke[0], stroke[1], marker='.', color='black')\n",
    "            plt.title(label)\n",
    "            plt.axis('off')\n",
    "    plt.show()    \n",
    "    \n",
    "# Convert drawings to images\n",
    "def draw_it(raw_strokes, output_height, output_width):\n",
    "    image = Image.new(\"P\", (255,255)\n",
    "#                       , color=1\n",
    "            )\n",
    "    image_draw = ImageDraw.Draw(image)\n",
    "\n",
    "    for stroke in raw_strokes:\n",
    "        for i in range(len(stroke[0])-1):\n",
    "\n",
    "            image_draw.line([stroke[0][i], \n",
    "                             stroke[1][i],\n",
    "                             stroke[0][i+1], \n",
    "                             stroke[1][i+1]],\n",
    "                            fill=255, width=6)\n",
    "    # Reduce image size\n",
    "    image = image.resize((output_height,output_width),Image.ANTIALIAS)\n",
    "    \n",
    "    return np.array(image)\n",
    "\n",
    "# Show an image from the dataframe\n",
    "def showImgFromDf(df, index):\n",
    "    # Show an image\n",
    "    plt.imshow(df.iloc[index]['img'],cmap='gray')\n",
    "    plt.title(df.iloc[index]['word'])\n",
    "    plt.show()\n",
    "    \n",
    "def CNN_dataPrep(train_df, img_height, img_width):\n",
    "    \n",
    "    num_classes = train_df['word'].nunique()\n",
    "    # Data Preprocessing\n",
    "\n",
    "    # Shuffle the data\n",
    "    random.seed(111)\n",
    "    train_df = train_df.sample(train_df.shape[0])\n",
    "    \n",
    "    # input image dimensions\n",
    "    img_rows, img_cols = img_height, img_width\n",
    "    input_shape = (img_rows, img_cols)\n",
    "    \n",
    "    # Reshape the array\n",
    "    imgArr = np.vstack(train_df['img'].values).flatten().reshape((train_df['img'].shape[0], img_rows, img_cols))\n",
    "#     imgArr_test = np.vstack(test_df['img'].values).flatten().reshape((test_df['img'].shape[0], img_rows, img_cols))\n",
    "    \n",
    "    # In Keras, the layers used for two-dimensional convolutions expect pixel values with the dimensions [width][height][pixels] for TF.\n",
    "    # In the case of RGB, the first dimension pixels would be 3 for the red, green and blue components and it would be like having 3 image inputs for every color image. In this case, the pixel values are gray scale, the pixel dimension is set to 1.\n",
    "    imgArr = imgArr.reshape(imgArr.shape[0], img_rows, img_cols, 1).astype('float32')\n",
    "#     imgArr_test = imgArr_test.reshape(imgArr_test.shape[0], img_rows, img_cols, 1).astype('float32')\n",
    "    \n",
    "    # Initialize the y_train\n",
    "    y_train = train_df['word']\n",
    "    \n",
    "    # Convert class labels from categorical to numerical\n",
    "    unique_classes_list = y_train.unique()\n",
    "    map_class_to_numeric = {k: v for v, k in enumerate(y_train.unique())}\n",
    "    map_numeric_to_class = {v: k for k, v in map_class_to_numeric.iteritems()}\n",
    "    y_train_numeric = y_train.apply(lambda x: map_class_to_numeric[x])\n",
    "\n",
    "    # convert class vectors to binary class matrices\n",
    "    y_train_one_hot = keras.utils.to_categorical(y_train_numeric, num_classes)\n",
    "    num_classes = y_train_one_hot.shape[1]\n",
    "    \n",
    "#     X_train, X_test, y_train, y_test = train_test_split(imgArr, y_train_one_hot, test_size=0.2)\n",
    "    \n",
    "    return imgArr, 'X_test', y_train_one_hot, 'y_test', 'imgArr_test', map_class_to_numeric, map_numeric_to_class\n",
    "    \n",
    "    \n",
    "def top_3_accuracy(y_true, y_pred):\n",
    "    return metrics.top_k_categorical_accuracy(y_true, y_pred, k=3)\n",
    "\n",
    "\n",
    "def baseline_conv_model(num_filters, num_classes, img_rows, img_cols):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(num_filters, (5,5), input_shape=(img_rows,img_cols,1), activation='relu')) \n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(num_filters*2, (5,5), activation='relu')) \n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(num_filters*4, (3,3), activation='relu')) \n",
    "    # model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#     model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1000, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(500, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "#     model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.add(Dense(units=num_classes))\n",
    "#     model.add(Activation('softmax'))\n",
    "    model.add(Activation(tf.nn.softmax))\n",
    "\n",
    "    # Compile\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', top_3_accuracy, 'categorical_crossentropy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.81 s, sys: 290 ms, total: 3.1 s\n",
      "Wall time: 3.26 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "recordsPerTrainClass = 10\n",
    "skiprows = 0\n",
    "img_height = img_width = 32\n",
    "\n",
    "# Get data and transform drawing into image\n",
    "train_df, test_df = generateTrainData(img_height, img_width, recordsPerTrainClass, skiprows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19 ms, sys: 5.85 ms, total: 24.9 ms\n",
      "Wall time: 20.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Transform data for CNN\n",
    "X_train, X_test, y_train, y_test, imgArr_test, map_class_to_numeric, map_numeric_to_class = CNN_dataPrep(train_df, img_height, img_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # model = baseline_conv_model(4, 340, 32, 32)\n",
    "# numStartFilters = 8\n",
    "# model = baseline_conv_model(numStartFilters, numClasses, img_height, img_width)\n",
    "# model.fit_generator(\n",
    "#         generator=dataGenerator,\n",
    "#         epochs=1000,\n",
    "#         verbose=1,\n",
    "#         shuffle=False,\n",
    "#         validation_data=(X_test, y_test),\n",
    "# #         ,\n",
    "# #         use_multiprocessing=True,\n",
    "# )\n",
    "# #       steps_per_epoch=(num_training_samples // batch_size),\n",
    "# #       validation_data=my_validation_batch_generator,\n",
    "# #       validation_steps=(num_validation_samples // batch_size),\n",
    "# #       use_multiprocessing=False,\n",
    "# #       workers=16,\n",
    "# #       max_queue_size=32)\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time \n",
    "# recordsPerTrainClass = 4\n",
    "# skiprows = 0\n",
    "# img_height = img_width = 32\n",
    "\n",
    "# # Get data and transform drawing into image\n",
    "# train_df, test_df = generateTrainData(img_height, img_width, recordsPerTrainClass, skiprows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # Transform data for CNN\n",
    "# X_train, X_test, y_train, y_test, imgArr_test, map_class_to_numeric, map_numeric_to_class = CNN_dataPrep(train_df, img_height, img_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_filters = 2\n",
    "# num_classes = 340\n",
    "# continueTrain = False\n",
    "# if continueTrain == False:\n",
    "#     model = baseline_conv_model(num_filters, num_classes, img_height, img_width)\n",
    "\n",
    "# # checkpoint\n",
    "# filepath=\"Saved_Models/weights.best.hdf5\"\n",
    "# checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "# callbacks = [checkpoint]\n",
    "\n",
    "# print(model.summary())\n",
    "\n",
    "# hist = model.fit(X_train, \n",
    "#           y_train, \n",
    "#           validation_data=(X_test, y_test),\n",
    "#           epochs=2, \n",
    "#           batch_size=5, \n",
    "#           verbose=2,\n",
    "#           callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "# print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))\n",
    "# # model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112199/112199 [00:22<00:00, 4887.68it/s]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "preds = model.predict(imgArr_test)\n",
    "outputDf = test_df.copy()[['key_id']]\n",
    "outputDf['word'] = ''\n",
    "map_numeric_to_class_space_normal = map_numeric_to_class.copy()\n",
    "for key in map_numeric_to_class_space_normal:\n",
    "    map_numeric_to_class_space_normal[key] = (map_numeric_to_class_space_normal[key].replace(\" \", \"_\"))\n",
    "\n",
    "for i in tqdm(range(preds.shape[0])):\n",
    "    outputDf['word'].at[i] = ' '.join(([map_numeric_to_class_space_normal[predClass] for predClass in [tup[1] for tup in sorted(zip(preds[i], range(340)), reverse=True)[:3]]]))\n",
    "\n",
    "# Create csv\n",
    "outputDf.to_csv('initial_pred.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open((\"Saved_Models/model_\" + str(datetime.today())[:16].replace(\" \", \"_\").replace(\":\",\"-\") + \".json\"), \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights((\"Saved_Models/model_\" + str(datetime.today())[:16].replace(\" \", \"_\").replace(\":\",\"-\") + \".h5\"))\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "# Load the model back\n",
    "# load json and create model\n",
    "json_file = open('Saved_Models/model_2018-11-09_22-07.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"Saved_Models/model_2018-11-09_22-07.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    " \n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', top_3_accuracy, 'categorical_crossentropy'])\n",
    "# score = loaded_model.evaluate(X, Y, verbose=0)\n",
    "# print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))\n",
    "model = loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateTrainData(output_height, output_width, recordsPerTrainClass, skiprows=0):\n",
    "\n",
    "    test_df = pd.read_csv('test_simplified.csv')\n",
    "\n",
    "    # Get names of all train csv files with the pattern match below\n",
    "    fnames = glob('train_simplified/*.csv')\n",
    "\n",
    "    rows = recordsPerTrainClass\n",
    "    # Get n rows from all the csv files and append them into one dataframe\n",
    "    train_df = pd.DataFrame(columns=pd.read_csv(fnames[0], nrows=1).columns)\n",
    "    for name in fnames:\n",
    "        if skiprows == 0:\n",
    "            data = pd.read_csv(name, nrows=recordsPerTrainClass)\n",
    "        else:\n",
    "            data = pd.read_csv(name, nrows=recordsPerTrainClass, skiprows=range(1,skiprows))\n",
    "        train_df = train_df.append(data)\n",
    "\n",
    "#     print(train_df.shape)\n",
    "        \n",
    "    train_df = train_df.reset_index().drop('index', axis=1)\n",
    "    # Get only those which were correctly recognized\n",
    "    train_df = train_df[train_df['recognized'] == True]\n",
    "    \n",
    "    # Convert the drawing column to matrix\n",
    "#     train_df['drawing'] = train_df['drawing'].apply(ast.literal_eval)\n",
    "#     test_df['drawing'] = test_df['drawing'].apply(ast.literal_eval)\n",
    "    train_df['drawing'] = train_df['drawing'].apply(eval)\n",
    "    test_df['drawing'] = test_df['drawing'].apply(eval)\n",
    "\n",
    "    # Convert drawing to images\n",
    "    train_df['img'] = train_df['drawing'].apply(lambda x: draw_it(x, output_height, output_width))\n",
    "    test_df['img'] = test_df['drawing'].apply(lambda x: draw_it(x, output_height, output_width))\n",
    "    # train_df['img'] = train_df[['drawing']].apply(lambda x: draw_it(x['drawing'], output_height, output_width), axis=1)\n",
    "    # test_df['img'] = test_df[['drawing']].apply(lambda x: draw_it(x['drawing'], output_height, output_width), axis=1)\n",
    "    \n",
    "    return train_df, test_df\n",
    "    \n",
    "def showSampleImgs():\n",
    "    n_samp = 3\n",
    "    train_df_sample = train_df.sample(n_samp)\n",
    "    plt.figure(figsize=(4,4))\n",
    "    for i in range(n_samp):\n",
    "        draw = train_df_sample.iloc[i]['drawing']\n",
    "        label = train_df_sample.iloc[i]['word']\n",
    "        plt.subplot(n_samp,1,i+1)\n",
    "        for stroke in draw:\n",
    "            plt.plot(stroke[0], stroke[1], marker='.', color='black')\n",
    "            plt.title(label)\n",
    "            plt.axis('off')\n",
    "    plt.show()    \n",
    "    \n",
    "# Convert drawings to images\n",
    "def draw_it(raw_strokes, output_height, output_width):\n",
    "    image = Image.new(\"P\", (255,255)\n",
    "#                       , color=1\n",
    "            )\n",
    "    image_draw = ImageDraw.Draw(image)\n",
    "\n",
    "    for stroke in raw_strokes:\n",
    "        for i in range(len(stroke[0])-1):\n",
    "\n",
    "            image_draw.line([stroke[0][i], \n",
    "                             stroke[1][i],\n",
    "                             stroke[0][i+1], \n",
    "                             stroke[1][i+1]],\n",
    "                            fill=255, width=6)\n",
    "    # Reduce image size\n",
    "    image = image.resize((output_height,output_width),Image.ANTIALIAS)\n",
    "    \n",
    "    return np.array(image)\n",
    "\n",
    "# Show an image from the dataframe\n",
    "def showImgFromDf(df, index):\n",
    "    # Show an image\n",
    "    plt.imshow(df.iloc[index]['img'],cmap='gray')\n",
    "    plt.title(df.iloc[index]['word'])\n",
    "    plt.show()\n",
    "    \n",
    "def CNN_dataPrep(train_df, img_height, img_width):\n",
    "    \n",
    "    num_classes = train_df['word'].nunique()\n",
    "    # Data Preprocessing\n",
    "\n",
    "    # Shuffle the data\n",
    "    random.seed(111)\n",
    "    train_df = train_df.sample(train_df.shape[0])\n",
    "    \n",
    "    # input image dimensions\n",
    "    img_rows, img_cols = img_height, img_width\n",
    "    input_shape = (img_rows, img_cols)\n",
    "    \n",
    "    # Reshape the array\n",
    "    imgArr = np.vstack(train_df['img'].values).flatten().reshape((train_df['img'].shape[0], img_rows, img_cols))\n",
    "    imgArr_test = np.vstack(test_df['img'].values).flatten().reshape((test_df['img'].shape[0], img_rows, img_cols))\n",
    "    \n",
    "    # In Keras, the layers used for two-dimensional convolutions expect pixel values with the dimensions [width][height][pixels] for TF.\n",
    "    # In the case of RGB, the first dimension pixels would be 3 for the red, green and blue components and it would be like having 3 image inputs for every color image. In this case, the pixel values are gray scale, the pixel dimension is set to 1.\n",
    "    imgArr = imgArr.reshape(imgArr.shape[0], img_rows, img_cols, 1).astype('float32')\n",
    "    imgArr_test = imgArr_test.reshape(imgArr_test.shape[0], img_rows, img_cols, 1).astype('float32')\n",
    "    \n",
    "    # Initialize the y_train\n",
    "    y_train = train_df['word']\n",
    "    \n",
    "    # Convert class labels from categorical to numerical\n",
    "    unique_classes_list = y_train.unique()\n",
    "    map_class_to_numeric = {k: v for v, k in enumerate(y_train.unique())}\n",
    "    map_numeric_to_class = {v: k for k, v in map_class_to_numeric.iteritems()}\n",
    "    y_train_numeric = y_train.apply(lambda x: map_class_to_numeric[x])\n",
    "\n",
    "    # convert class vectors to binary class matrices\n",
    "    y_train_one_hot = keras.utils.to_categorical(y_train_numeric, num_classes)\n",
    "    num_classes = y_train_one_hot.shape[1]\n",
    "    \n",
    "#     X_train, X_test, y_train, y_test = train_test_split(imgArr, y_train_one_hot, test_size=0.2)\n",
    "    \n",
    "    return imgArr, 'X_test', y_train_one_hot, 'y_test', 'imgArr_test', 'map_class_to_numeric', 'map_numeric_to_class'\n",
    "    \n",
    "    \n",
    "def top_3_accuracy(y_true, y_pred):\n",
    "    return metrics.top_k_categorical_accuracy(y_true, y_pred, k=3)\n",
    "\n",
    "\n",
    "# def baseline_conv_model(num_filters, num_classes, img_rows, img_cols):\n",
    "#     model = Sequential()\n",
    "#     model.add(Conv2D(num_filters, (5,5), input_shape=(img_rows,img_cols,1), activation='relu')) \n",
    "#     model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#     model.add(Dropout(0.2))\n",
    "#     model.add(Conv2D(num_filters*2, (5,5), input_shape=(img_rows,img_cols,1), activation='relu')) \n",
    "#     model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#     model.add(Dropout(0.2))\n",
    "#     model.add(Conv2D(num_filters*2, (3,3), input_shape=(img_rows,img_cols,1), activation='relu')) \n",
    "#     # model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#     model.add(Dropout(0.2))\n",
    "#     model.add(Flatten())\n",
    "#     model.add(Dense(1000, activation='relu'))\n",
    "#     model.add(Dropout(0.2))\n",
    "#     model.add(Dense(500, activation='relu'))\n",
    "#     model.add(Dropout(0.2))\n",
    "# #     model.add(Dense(num_classes, activation='softmax'))\n",
    "#     model.add(Dense(units=num_classes))\n",
    "# #     model.add(Activation('softmax'))\n",
    "#     model.add(Activation(tf.nn.softmax))\n",
    "\n",
    "#     # Compile\n",
    "#     model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', top_3_accuracy, 'categorical_crossentropy'])\n",
    "#     return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_it(raw_strokes, output_height, output_width):\n",
    "    image = Image.new(\"P\", (255,255)\n",
    "#                       , color=1\n",
    "            )\n",
    "    image_draw = ImageDraw.Draw(image)\n",
    "\n",
    "    for stroke in raw_strokes:\n",
    "        for i in range(len(stroke[0])-1):\n",
    "\n",
    "            image_draw.line([stroke[0][i], \n",
    "                             stroke[1][i],\n",
    "                             stroke[0][i+1], \n",
    "                             stroke[1][i+1]],\n",
    "                            fill=255, width=6)\n",
    "    # Reduce image size\n",
    "    image = image.resize((output_height,output_width),Image.ANTIALIAS)\n",
    "    \n",
    "    return np.array(image)\n",
    "\n",
    "recordsPerTrainClass = 5\n",
    "skiprows = 0\n",
    "img_height = img_width = 32\n",
    "\n",
    "# Get data and transform drawing into image\n",
    "train_df, test_df = generateTrainData(img_height, img_width, recordsPerTrainClass, skiprows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 347 ms, sys: 221 ms, total: 569 ms\n",
      "Wall time: 581 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Transform data for CNN\n",
    "X_train, X_test, y_train, y_test, imgArr_test, map_class_to_numeric, map_numeric_to_class = CNN_dataPrep(train_df, img_height, img_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pppp_train = X_train\n",
    "pppp_y = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
